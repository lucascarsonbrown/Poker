# Poker AI Algorithm

The AI uses Counterfactual Regret Minimization (CFR) to compute Nash equilibrium strategies through millions of self-play iterations. During training, CFR traverses every possible game state, tracking "regret" for each action not taken—if an action would have performed better than the chosen action, its regret increases. The current strategy is computed via regret matching: actions with higher regret get higher probability, causing the AI to explore better moves over time. The time-averaged strategy across all iterations provably converges to a Nash equilibrium (unexploitable strategy). At runtime, the AI maps the current hand to a pre-computed information set using card abstraction (169 lossless preflop clusters based on rank/suit patterns, plus equity-based postflop clusters computed via Monte Carlo simulation—running thousands of random rollouts to estimate winning probability). It then looks up the trained strategy for that information set and samples an action from the probability distribution. If no trained strategy exists for a given situation, it falls back to equity-based heuristics that compare hand equity against pot odds to decide whether to fold, call, or raise.
